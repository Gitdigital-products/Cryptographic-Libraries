#include "sha2.h"
#include <string.h>
#include <stdint.h>

// Check for compiler-specific features
#if defined(__GNUC__) || defined(__clang__)
#define ALWAYS_INLINE __attribute__((always_inline)) inline
#define RESTRICT __restrict
#else
#define ALWAYS_INLINE inline
#define RESTRICT
#endif

// Platform detection
#if defined(__x86_64__) || defined(_M_X64)
#define SHA256_X86_64 1
#elif defined(__aarch64__) || defined(_M_ARM64)
#define SHA256_ARM64 1
#endif

// Generic optimized implementation using loop unrolling
ALWAYS_INLINE static void sha256_compress_opt(uint32_t state[8], const uint8_t block[64]) {
    uint32_t W[64];
    uint32_t a, b, c, d, e, f, g, h;
    
    // Load message schedule (16 words)
    for (int i = 0; i < 16; i++) {
        W[i] = be32dec(&block[i * 4]);
    }
    
    // Extend message schedule
    for (int i = 16; i < 64; i++) {
        W[i] = gamma1(W[i-2]) + W[i-7] + gamma0(W[i-15]) + W[i-16];
    }
    
    // Initialize working variables
    a = state[0];
    b = state[1];
    c = state[2];
    d = state[3];
    e = state[4];
    f = state[5];
    g = state[6];
    h = state[7];
    
    // Unrolled compression loop (8 rounds per iteration)
    for (int i = 0; i < 64; i += 8) {
        // Round 1
        uint32_t T1 = h + sigma1(e) + ch(e, f, g) + K[i] + W[i];
        uint32_t T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        // Round 2
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+1] + W[i+1];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        // Rounds 3-8...
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+2] + W[i+2];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+3] + W[i+3];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+4] + W[i+4];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+5] + W[i+5];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+6] + W[i+6];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
        
        T1 = h + sigma1(e) + ch(e, f, g) + K[i+7] + W[i+7];
        T2 = sigma0(a) + maj(a, b, c);
        h = g; g = f; f = e; e = d + T1;
        d = c; c = b; b = a; a = T1 + T2;
    }
    
    // Update state
    state[0] += a; state[1] += b; state[2] += c; state[3] += d;
    state[4] += e; state[5] += f; state[6] += g; state[7] += h;
    
    // Clear sensitive data
    memset(W, 0, sizeof(W));
    a = b = c = d = e = f = g = h = 0;
}

#if SHA256_X86_64
// x86-64 SSE4.1/SHA extensions optimized version
#include <immintrin.h>

ALWAYS_INLINE static void sha256_compress_x86_64(uint32_t state[8], const uint8_t block[64]) {
    // This is a simplified version - real implementation would use
    // Intel SHA extensions if available (sha256rnds2 instruction)
    
    // For now, use the optimized generic version
    sha256_compress_opt(state, block);
}
#endif

#if SHA256_ARM64
// ARM64 NEON optimized version
#include <arm_neon.h>

ALWAYS_INLINE static void sha256_compress_arm64(uint32_t state[8], const uint8_t block[64]) {
    // ARMv8.2-A SHA3 extensions would be used here
    // For now, use the optimized generic version
    sha256_compress_opt(state, block);
}
#endif

// Dispatch to appropriate implementation
void sha256_compress(uint32_t state[8], const uint8_t block[64]) {
#if SHA256_X86_64
    sha256_compress_x86_64(state, block);
#elif SHA256_ARM64
    sha256_compress_arm64(state, block);
#else
    sha256_compress_opt(state, block);
#endif
}

// Optimized memory operations
ALWAYS_INLINE static void secure_zero(void *ptr, size_t len) {
#if defined(__STDC_LIB_EXT1__) && __STDC_WANT_LIB_EXT1__
    memset_s(ptr, len, 0, len);
#else
    volatile unsigned char *p = (volatile unsigned char *)ptr;
    while (len--) {
        *p++ = 0;
    }
#endif
}